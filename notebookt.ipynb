{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\utilisateur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\utilisateur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\utilisateur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from mail_manager import mail_manager\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import os\n",
    "import nltk.corpus\n",
    "from nltk import *\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "import matplotlib.pyplot as plt\n",
    "from text_functions import CleanText\n",
    "import pdb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "In  \u001b[0;34m[7]\u001b[0m:\nLine \u001b[0;34m1\u001b[0m:     maildir = Path(\u001b[33m\"\u001b[39;49;00m\u001b[33mC:/Users/utilisateur/TP Scandale Enron/maildir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Path' is not defined\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "maildir = Path(\"C:/Users/utilisateur/TP Scandale Enron/maildir\")\n",
    "manager = mail_manager(maildir)\n",
    "manager.export_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:/Users/utilisateur/TP Scandale Enron/Projet Enron/master/user_csv/beck-s.csv\", \"r\", encoding=\"utf-8\") as file :\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',',\n",
       " 'path',\n",
       " ',',\n",
       " 'from_address',\n",
       " ',',\n",
       " 'from_name',\n",
       " ',',\n",
       " 'to_address',\n",
       " ',',\n",
       " 'to_name',\n",
       " ',',\n",
       " 'cc',\n",
       " ',',\n",
       " 'bcc',\n",
       " ',',\n",
       " 'content',\n",
       " ',',\n",
       " 'title',\n",
       " ',',\n",
       " 'date',\n",
       " ',',\n",
       " 'origin',\n",
       " ',',\n",
       " 'file',\n",
       " '0',\n",
       " ',',\n",
       " 'D',\n",
       " ':',\n",
       " '\\\\Dataset',\n",
       " 'ENRON\\\\maildir\\\\beck-s\\\\2001_plan\\\\1',\n",
       " ',',\n",
       " 'david.delainey',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'David',\n",
       " 'W',\n",
       " 'Delainey',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wes.colwell',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'sally.beck',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'david.oxley',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'mark.haedicke',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'eric.thode',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'stephen.douglass',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'vince.kaminski',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'scott.tholan',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'brian.redmond',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'joseph.deffner',\n",
       " '@',\n",
       " 'enron.com',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Wes',\n",
       " 'Colwell',\n",
       " ',',\n",
       " 'Sally',\n",
       " 'Beck',\n",
       " ',',\n",
       " 'David',\n",
       " 'Oxley',\n",
       " ',',\n",
       " 'Mark',\n",
       " 'E',\n",
       " 'Haedicke',\n",
       " ',',\n",
       " 'Eric',\n",
       " 'Thode',\n",
       " ',',\n",
       " 'Stephen',\n",
       " 'Douglass',\n",
       " ',',\n",
       " 'Vince',\n",
       " 'J',\n",
       " 'Kaminski',\n",
       " ',',\n",
       " 'Scott',\n",
       " 'Tholan',\n",
       " ',',\n",
       " 'Brian',\n",
       " 'Redmond',\n",
       " ',',\n",
       " 'Joseph',\n",
       " 'Deffner',\n",
       " \"''\",\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " \"''\",\n",
       " 'Guys',\n",
       " ',',\n",
       " 'attached',\n",
       " 'you',\n",
       " 'will',\n",
       " 'find',\n",
       " 'a',\n",
       " 'final',\n",
       " 'cut',\n",
       " 'on',\n",
       " 'the',\n",
       " 'ENA',\n",
       " '2001',\n",
       " 'expense',\n",
       " 'budget',\n",
       " '.',\n",
       " 'Please',\n",
       " 'review',\n",
       " 'and',\n",
       " 'make',\n",
       " 'any',\n",
       " 'adjustments',\n",
       " 'to',\n",
       " 'your',\n",
       " 'existing',\n",
       " 'plan',\n",
       " 'that',\n",
       " 'are',\n",
       " 'appropriate',\n",
       " 'to',\n",
       " 'hit',\n",
       " 'the',\n",
       " 'net',\n",
       " 'ENA',\n",
       " 'target',\n",
       " '.',\n",
       " 'In',\n",
       " 'order',\n",
       " 'to',\n",
       " 'stay',\n",
       " 'flat',\n",
       " 'year',\n",
       " 'on',\n",
       " 'year',\n",
       " ',',\n",
       " 'I',\n",
       " 'split',\n",
       " 'the',\n",
       " 'remaining',\n",
       " 'positive',\n",
       " 'variance',\n",
       " 'equally',\n",
       " 'across',\n",
       " 'the',\n",
       " 'groups',\n",
       " '.',\n",
       " 'As',\n",
       " 'we',\n",
       " 'had',\n",
       " 'discussed',\n",
       " 'earlier',\n",
       " ',',\n",
       " 'these',\n",
       " 'costs',\n",
       " 'will',\n",
       " 'not',\n",
       " 'be',\n",
       " 'allocated',\n",
       " 'to',\n",
       " 'the',\n",
       " 'business',\n",
       " 'units',\n",
       " 'and',\n",
       " 'will',\n",
       " 'be',\n",
       " 'tracked',\n",
       " 'on',\n",
       " 'the',\n",
       " 'ENA',\n",
       " 'income',\n",
       " 'statement',\n",
       " 'below',\n",
       " 'the',\n",
       " 'line',\n",
       " 'and',\n",
       " 'the',\n",
       " 'accountability',\n",
       " 'managed',\n",
       " 'by',\n",
       " 'each',\n",
       " 'of',\n",
       " 'you',\n",
       " '.',\n",
       " 'All',\n",
       " 'outside',\n",
       " 'variable',\n",
       " 'costs',\n",
       " ',',\n",
       " 'specifically',\n",
       " 'related',\n",
       " 'to',\n",
       " 'specific',\n",
       " 'deals',\n",
       " ',',\n",
       " 'will',\n",
       " 'be',\n",
       " 'charged',\n",
       " 'to',\n",
       " 'the',\n",
       " 'business',\n",
       " 'units',\n",
       " 'eg',\n",
       " ')',\n",
       " 'outside',\n",
       " 'legal',\n",
       " 'and',\n",
       " 'tax',\n",
       " ',',\n",
       " 'outside',\n",
       " 'technical',\n",
       " 'expertise',\n",
       " ',',\n",
       " 'facility',\n",
       " 'costs',\n",
       " ',',\n",
       " 'outside',\n",
       " 'research',\n",
       " 'support',\n",
       " ',',\n",
       " 'incremental',\n",
       " 'back',\n",
       " 'and',\n",
       " 'mid',\n",
       " 'office',\n",
       " 'support',\n",
       " 'for',\n",
       " 'specific',\n",
       " 'asset',\n",
       " 'management',\n",
       " 'deals',\n",
       " ',',\n",
       " 'specific',\n",
       " 'entertainment',\n",
       " ',',\n",
       " 'etc',\n",
       " '.',\n",
       " 'I',\n",
       " 'look',\n",
       " 'at',\n",
       " 'this',\n",
       " 'cost',\n",
       " 'structure',\n",
       " 'as',\n",
       " 'the',\n",
       " 'minimum',\n",
       " 'capacity',\n",
       " 'charge',\n",
       " 'we',\n",
       " 'need',\n",
       " 'to',\n",
       " 'operate',\n",
       " 'our',\n",
       " 'business',\n",
       " 'and',\n",
       " 'evaluate/manage',\n",
       " 'our',\n",
       " 'risks',\n",
       " '.',\n",
       " 'Wes',\n",
       " ',',\n",
       " 'can',\n",
       " 'you',\n",
       " 'please',\n",
       " 'finalize',\n",
       " 'the',\n",
       " 'one',\n",
       " 'page',\n",
       " 'plan',\n",
       " '(',\n",
       " 'expenses',\n",
       " 'and',\n",
       " 'headcount',\n",
       " ')',\n",
       " 'for',\n",
       " 'each',\n",
       " 'group',\n",
       " 'with',\n",
       " 'these',\n",
       " 'changes',\n",
       " '.',\n",
       " 'Regards',\n",
       " 'Delainey',\n",
       " \"''\",\n",
       " ',2001',\n",
       " 'Group',\n",
       " 'Expenses',\n",
       " ',',\n",
       " \"''\",\n",
       " 'Thu',\n",
       " ',',\n",
       " '9',\n",
       " 'Nov',\n",
       " '2000',\n",
       " '10:44:00',\n",
       " '-0800',\n",
       " '(',\n",
       " 'PST',\n",
       " ')',\n",
       " \"''\",\n",
       " ',',\n",
       " 'Beck-S',\n",
       " ',',\n",
       " '\\\\Sally_Beck_Dec2000\\\\Notes',\n",
       " 'Folders\\\\2001',\n",
       " 'plansbeck.nsf',\n",
       " '1',\n",
       " ',',\n",
       " 'D',\n",
       " ':',\n",
       " '\\\\Dataset',\n",
       " 'ENRON\\\\maildir\\\\beck-s\\\\2001_plan\\\\2',\n",
       " ',',\n",
       " 'holly.heath',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'Holly',\n",
       " 'Heath',\n",
       " ',',\n",
       " \"''\",\n",
       " 'robert.superty',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'diane.cook',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'heather.choate',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'bob.hall',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'leslie.reeves',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'yolanda.ford',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'jefferson.sorenson',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'kim.weldon',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'shona.wilson',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'maria.sandoval',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'eugenio.perez',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'michael.moscoso',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'sally.beck',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'patti.thompson',\n",
       " '@',\n",
       " 'enron.com',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Robert',\n",
       " 'Superty',\n",
       " ',',\n",
       " 'Diane',\n",
       " 'H',\n",
       " 'Cook',\n",
       " ',',\n",
       " 'Heather',\n",
       " 'Choate',\n",
       " ',',\n",
       " 'Bob',\n",
       " 'M',\n",
       " 'Hall',\n",
       " ',',\n",
       " 'Leslie',\n",
       " 'Reeves',\n",
       " ',',\n",
       " 'Yolanda',\n",
       " 'Ford',\n",
       " ',',\n",
       " 'Jefferson',\n",
       " 'D',\n",
       " 'Sorenson',\n",
       " ',',\n",
       " 'Kim',\n",
       " 'Weldon',\n",
       " ',',\n",
       " 'Shona',\n",
       " 'Wilson',\n",
       " ',',\n",
       " 'Maria',\n",
       " 'Sandoval',\n",
       " ',',\n",
       " 'Eugenio',\n",
       " 'Perez',\n",
       " ',',\n",
       " 'Michael',\n",
       " 'E',\n",
       " 'Moscoso',\n",
       " ',',\n",
       " 'Sally',\n",
       " 'Beck',\n",
       " ',',\n",
       " 'Patti',\n",
       " 'Thompson',\n",
       " \"''\",\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " \"''\",\n",
       " 'I',\n",
       " 'am',\n",
       " 'still',\n",
       " 'in',\n",
       " 'need',\n",
       " 'of',\n",
       " 'the',\n",
       " 'information',\n",
       " 'regarding',\n",
       " 'Global',\n",
       " 'Markets',\n",
       " 'Plan',\n",
       " '.',\n",
       " '(',\n",
       " 'See',\n",
       " 'prior',\n",
       " 'E-mail',\n",
       " ')',\n",
       " 'If',\n",
       " 'you',\n",
       " 'are',\n",
       " 'in',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'following',\n",
       " 'groups',\n",
       " ',',\n",
       " 'could',\n",
       " 'you',\n",
       " 'please',\n",
       " 'respond',\n",
       " 'with',\n",
       " 'your',\n",
       " 'breakdown',\n",
       " 'as',\n",
       " 'soon',\n",
       " 'as',\n",
       " 'possible',\n",
       " ':',\n",
       " 'Logistics',\n",
       " '(',\n",
       " '2',\n",
       " 'Cost',\n",
       " 'centers',\n",
       " 'needed',\n",
       " ')',\n",
       " 'Settlements',\n",
       " 'and',\n",
       " 'Confirmations',\n",
       " '(',\n",
       " '3',\n",
       " 'cost',\n",
       " 'centers',\n",
       " 'needed',\n",
       " ')',\n",
       " 'Risk',\n",
       " 'Management',\n",
       " 'and',\n",
       " 'Controls',\n",
       " '(',\n",
       " '3',\n",
       " 'cost',\n",
       " 'centers',\n",
       " 'needed',\n",
       " ')',\n",
       " 'Energy',\n",
       " 'Operations',\n",
       " 'management',\n",
       " '(',\n",
       " '1',\n",
       " 'cost',\n",
       " 'center',\n",
       " 'needed',\n",
       " ')',\n",
       " 'Thanks',\n",
       " 'so',\n",
       " 'much',\n",
       " '.',\n",
       " 'Please',\n",
       " 'call',\n",
       " 'if',\n",
       " 'you',\n",
       " 'have',\n",
       " 'any',\n",
       " 'questions',\n",
       " '.',\n",
       " 'Holly',\n",
       " '3-5843',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " 'Forwarded',\n",
       " 'by',\n",
       " 'Holly',\n",
       " 'Heath/Corp/Enron',\n",
       " 'on',\n",
       " '11/07/2000',\n",
       " '01:59',\n",
       " 'PM',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '-',\n",
       " 'Holly',\n",
       " 'Heath',\n",
       " '11/02/2000',\n",
       " '04:25',\n",
       " 'PM',\n",
       " 'To',\n",
       " ':',\n",
       " 'Robert',\n",
       " 'Superty/HOU/ECT',\n",
       " '@',\n",
       " 'ECT',\n",
       " ',',\n",
       " 'Diane',\n",
       " 'H',\n",
       " 'Cook/HOU/ECT',\n",
       " '@',\n",
       " 'ECT',\n",
       " ',',\n",
       " 'Heather',\n",
       " 'Choate/HOU/ECT',\n",
       " '@',\n",
       " 'ECT',\n",
       " ',',\n",
       " 'Bob',\n",
       " 'M',\n",
       " 'Hall/NA/Enron',\n",
       " '@',\n",
       " 'Enron',\n",
       " ',',\n",
       " 'Vanessa',\n",
       " 'Kyama/NA/Enron',\n",
       " '@',\n",
       " 'Enron',\n",
       " ',',\n",
       " 'Bob',\n",
       " 'M',\n",
       " 'Hall/NA/Enron',\n",
       " '@',\n",
       " 'Enron',\n",
       " ',',\n",
       " 'Sheri',\n",
       " 'Thomas/HOU/ECT',\n",
       " '@',\n",
       " 'ECT',\n",
       " ',',\n",
       " 'Lola',\n",
       " 'Willis/Corp/Enron',\n",
       " '@',\n",
       " 'ENRON',\n",
       " ',',\n",
       " 'Mary',\n",
       " 'Solmonson/HOU/ECT',\n",
       " '@',\n",
       " 'ECT',\n",
       " ',',\n",
       " 'Marvia',\n",
       " 'Jefferson/HOU/ECT',\n",
       " '@',\n",
       " 'ECT',\n",
       " ',',\n",
       " 'Julissa',\n",
       " 'Marron/Corp/Enron',\n",
       " '@',\n",
       " 'ENRON',\n",
       " ',',\n",
       " 'Sally',\n",
       " 'Beck/HOU/ECT',\n",
       " '@',\n",
       " 'ECT',\n",
       " ',',\n",
       " 'Patti',\n",
       " 'Thompson/HOU/ECT',\n",
       " '@',\n",
       " 'ECT',\n",
       " 'cc',\n",
       " ':',\n",
       " 'Subject',\n",
       " ':',\n",
       " 'Plan',\n",
       " '2001',\n",
       " '-',\n",
       " 'Global',\n",
       " 'Markets',\n",
       " 'Attached',\n",
       " 'is',\n",
       " 'a',\n",
       " 'file',\n",
       " 'containing',\n",
       " 'all',\n",
       " 'cost',\n",
       " 'centers',\n",
       " 'that',\n",
       " 'are',\n",
       " 'allocating',\n",
       " 'to',\n",
       " 'Global',\n",
       " 'Markets',\n",
       " 'in',\n",
       " 'the',\n",
       " 'year',\n",
       " '2001',\n",
       " '.',\n",
       " 'Could',\n",
       " 'I',\n",
       " 'please',\n",
       " 'get',\n",
       " 'from',\n",
       " 'you',\n",
       " 'a',\n",
       " 'breakdown',\n",
       " 'of',\n",
       " 'every',\n",
       " 'team',\n",
       " 'affected',\n",
       " 'by',\n",
       " 'Global',\n",
       " 'markets',\n",
       " '.',\n",
       " 'Please',\n",
       " 'explain',\n",
       " 'all',\n",
       " 'percentages',\n",
       " 'listed',\n",
       " 'in',\n",
       " 'column',\n",
       " '``',\n",
       " \"''\",\n",
       " 'A',\n",
       " \"''\",\n",
       " \"''\",\n",
       " ',',\n",
       " 'by',\n",
       " 'breaking',\n",
       " 'apart',\n",
       " 'into',\n",
       " 'columns',\n",
       " 'B',\n",
       " '-',\n",
       " 'J',\n",
       " '.',\n",
       " 'Please',\n",
       " 'feel',\n",
       " 'free',\n",
       " 'to',\n",
       " 'call',\n",
       " 'with',\n",
       " 'any',\n",
       " 'questions',\n",
       " 'you',\n",
       " 'may',\n",
       " 'have',\n",
       " '.',\n",
       " 'Thanks',\n",
       " 'so',\n",
       " 'much',\n",
       " 'for',\n",
       " 'your',\n",
       " 'help',\n",
       " '.',\n",
       " 'Please',\n",
       " 'submit',\n",
       " 'this',\n",
       " 'explanation',\n",
       " 'by',\n",
       " 'tomorrow',\n",
       " 'afternoon',\n",
       " '.',\n",
       " 'Thanks',\n",
       " 'again',\n",
       " 'for',\n",
       " 'your',\n",
       " 'help',\n",
       " '.',\n",
       " 'Holly',\n",
       " '3-5843',\n",
       " \"''\",\n",
       " ',',\n",
       " 'Plan',\n",
       " '2001',\n",
       " '-',\n",
       " 'Global',\n",
       " 'Markets',\n",
       " ',',\n",
       " \"''\",\n",
       " 'Tue',\n",
       " ',',\n",
       " '7',\n",
       " 'Nov',\n",
       " '2000',\n",
       " '06:10:00',\n",
       " '-0800',\n",
       " '(',\n",
       " 'PST',\n",
       " ')',\n",
       " \"''\",\n",
       " ',',\n",
       " 'Beck-S',\n",
       " ',',\n",
       " '\\\\Sally_Beck_Dec2000\\\\Notes',\n",
       " 'Folders\\\\2001',\n",
       " 'plansbeck.nsf',\n",
       " '2',\n",
       " ',',\n",
       " 'D',\n",
       " ':',\n",
       " '\\\\Dataset',\n",
       " 'ENRON\\\\maildir\\\\beck-s\\\\2001_plan\\\\3',\n",
       " ',',\n",
       " 'holly.heath',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'Holly',\n",
       " 'Heath',\n",
       " ',',\n",
       " \"''\",\n",
       " 'robert.superty',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'diane.cook',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'heather.choate',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'bob.hall',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'vanessa.kyama',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'bob.hall',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'sheri.thomas',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'lola.willis',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'mary.solmonson',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'marvia.jefferson',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'julissa.marron',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'sally.beck',\n",
       " '@',\n",
       " 'enron.com',\n",
       " ',',\n",
       " 'patti.thompson',\n",
       " '@',\n",
       " 'enron.com',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Robert',\n",
       " 'Superty',\n",
       " ',',\n",
       " 'Diane',\n",
       " 'H',\n",
       " 'Cook',\n",
       " ',',\n",
       " 'Heather',\n",
       " 'Choate',\n",
       " ',',\n",
       " 'Bob',\n",
       " 'M',\n",
       " 'Hall',\n",
       " ',',\n",
       " 'Vanessa',\n",
       " 'Kyama',\n",
       " ',',\n",
       " 'Bob',\n",
       " 'M',\n",
       " 'Hall',\n",
       " ',',\n",
       " 'Sheri',\n",
       " 'Thomas',\n",
       " ',',\n",
       " 'Lola',\n",
       " 'Willis',\n",
       " ',',\n",
       " 'Mary',\n",
       " 'Solmonson',\n",
       " ',',\n",
       " 'Marvia',\n",
       " 'Jefferson',\n",
       " ',',\n",
       " 'Julissa',\n",
       " 'Marron',\n",
       " ',',\n",
       " 'Sally',\n",
       " 'Beck',\n",
       " ',',\n",
       " 'Patti',\n",
       " 'Thompson',\n",
       " \"''\",\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " \"''\",\n",
       " 'Attached',\n",
       " 'is',\n",
       " 'a',\n",
       " 'file',\n",
       " 'containing',\n",
       " 'all',\n",
       " 'cost',\n",
       " 'centers',\n",
       " 'that',\n",
       " 'are',\n",
       " 'allocating',\n",
       " 'to',\n",
       " 'Global',\n",
       " 'Markets',\n",
       " 'in',\n",
       " 'the',\n",
       " 'year',\n",
       " '2001',\n",
       " '.',\n",
       " 'Could',\n",
       " 'I',\n",
       " 'please',\n",
       " 'get',\n",
       " 'from',\n",
       " 'you',\n",
       " 'a',\n",
       " 'breakdown',\n",
       " 'of',\n",
       " 'every',\n",
       " 'team',\n",
       " 'affected',\n",
       " 'by',\n",
       " 'Global',\n",
       " 'markets',\n",
       " '.',\n",
       " 'Please',\n",
       " 'explain',\n",
       " 'all',\n",
       " 'percentages',\n",
       " 'listed',\n",
       " 'in',\n",
       " 'column',\n",
       " '``',\n",
       " \"''\",\n",
       " 'A',\n",
       " \"''\",\n",
       " \"''\",\n",
       " ',',\n",
       " 'by',\n",
       " 'breaking',\n",
       " 'apart',\n",
       " 'into',\n",
       " 'columns',\n",
       " 'B',\n",
       " '-',\n",
       " 'J',\n",
       " '.',\n",
       " 'Please',\n",
       " 'feel',\n",
       " 'free',\n",
       " 'to',\n",
       " 'call',\n",
       " 'with',\n",
       " 'any',\n",
       " 'questions',\n",
       " 'you',\n",
       " 'may',\n",
       " 'have',\n",
       " '.',\n",
       " 'Thanks',\n",
       " 'so',\n",
       " 'much',\n",
       " 'for',\n",
       " 'your',\n",
       " 'help',\n",
       " '.',\n",
       " 'Please',\n",
       " 'submit',\n",
       " 'this',\n",
       " 'explanation',\n",
       " 'by',\n",
       " 'tomorrow',\n",
       " 'afternoon',\n",
       " '.',\n",
       " 'Thanks',\n",
       " 'again',\n",
       " 'for',\n",
       " 'your',\n",
       " 'help',\n",
       " '.',\n",
       " 'Holly',\n",
       " '3-5843',\n",
       " '``',\n",
       " ',',\n",
       " 'Plan',\n",
       " '2001',\n",
       " '-',\n",
       " 'Global',\n",
       " 'Markets',\n",
       " ',',\n",
       " \"''\",\n",
       " 'Thu',\n",
       " ',',\n",
       " '2',\n",
       " 'Nov',\n",
       " '2000',\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize \n",
    "token = word_tokenize(text)\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 446563, '@': 150993, '--': 109744, '.': 106409, 'the': 91305, \"''\": 90897, 'enron.com': 85883, 'to': 74342, ':': 67683, 'and': 55618, ...})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist(token)\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\utilisateur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "text_tokens = token\n",
    "tokens_without_sw = [word for word in text_tokens if not word in stopwords.words()]\n",
    "print(tokens_without_sw)\n",
    "#a = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "en_stopwords = set(stopwords.words('english'))\n",
    "text_tokens = token\n",
    "tokens_without_sw = [word for word in text_tokens if not word in en_stopwords]\n",
    "print(tokens_without_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokens_without_sw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d527aa2cc046>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Loading data - text file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokens_without_sw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mnewwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokens_without_sw' is not defined"
     ]
    }
   ],
   "source": [
    "# Loading Libraries\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "from nltk.metrics import TrigramAssocMeasures\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "# Loading data - text file\n",
    "words = tokens_without_sw\n",
    "newwords = []\n",
    "for word in words:\n",
    "    x = re.sub(r'[a-z]*', '', word)\n",
    "    if x: #if x renverra false si x est vide et ne l'integrera donc pas Ã  newwords\n",
    "        newwords.append(x)\n",
    "\n",
    "trigram_collocation = TrigramCollocationFinder.from_words(newwords)\n",
    "\n",
    "trigram_collocation.nbest(TrigramAssocMeasures.likelihood_ratio, 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
